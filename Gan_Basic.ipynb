{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "206ba81f-978a-4c31-9c3d-6ebe5a5bfc29"
      ],
      "provenance": [],
      "name": "Gan Basic.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daemonX10/Data-Science/blob/main/Gan_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Dependencies and Data"
      ],
      "metadata": {
        "id": "64f04b6a-fe54-41ce-92fe-ae94fc587387"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets"
      ],
      "metadata": {
        "tags": [],
        "id": "2tI2jB0-_1X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "tags": [],
        "id": "9wDWnD5C_1X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bringing in tensorflow\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "gA7gsEFH_1X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Brining in tensorflow datasets for fashion mnist\n",
        "import tensorflow_datasets as tfds\n",
        "# Bringing in matplotlib for viz stuff\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Fr9vS9dq_1X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the tensorflow datasets api to bring in the data source\n",
        "ds = tfds.load('fashion_mnist', split='train')"
      ],
      "metadata": {
        "id": "yOtmyEe6_1X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.as_numpy_iterator().next()['label']"
      ],
      "metadata": {
        "id": "EWMdWt5u_1YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Viz Data and Build Dataset"
      ],
      "metadata": {
        "id": "ea1635e4-4beb-493d-92c1-b106c806ca70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do some data transformation\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Zx1-YOth_1YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup connection aka iterator\n",
        "dataiterator = ds.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "4W_ah0O7_1YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting data out of the pipeline\n",
        "dataiterator.next()['image']"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "-86mJ5Z-_1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the subplot formatting\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "# Loop four times and get images\n",
        "for idx in range(4):\n",
        "    # Grab an image and label\n",
        "    sample = dataiterator.next()\n",
        "    # Plot the image using a specific subplot\n",
        "    ax[idx].imshow(np.squeeze(sample['image']))\n",
        "    # Appending the image label as the plot title\n",
        "    ax[idx].title.set_text(sample['label'])"
      ],
      "metadata": {
        "id": "7QHnquW0_1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale and return images only\n",
        "def scale_images(data):\n",
        "    image = data['image']\n",
        "    return image / 255"
      ],
      "metadata": {
        "id": "nILZ3Xzu_1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the dataset\n",
        "ds = tfds.load('fashion_mnist', split='train')\n",
        "# Running the dataset through the scale_images preprocessing step\n",
        "ds = ds.map(scale_images)\n",
        "# Cache the dataset for that batch\n",
        "ds = ds.cache()\n",
        "# Shuffle it up\n",
        "ds = ds.shuffle(60000)\n",
        "# Batch into 128 images per sample\n",
        "ds = ds.batch(128)\n",
        "# Reduces the likelihood of bottlenecking\n",
        "ds = ds.prefetch(64)"
      ],
      "metadata": {
        "id": "fpxcvym9_1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.as_numpy_iterator().next().shape"
      ],
      "metadata": {
        "id": "Rp4HQZY5_1YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Build Neural Network"
      ],
      "metadata": {
        "id": "9a5b08df-7b20-41f4-a8ff-112dface1cb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Import Modelling Components"
      ],
      "metadata": {
        "id": "38f66add-a3db-467f-96c3-f87b9f880159"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bring in the sequential api for the generator and discriminator\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Bring in the layers for the neural network\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
      ],
      "metadata": {
        "id": "3vuAqdxx_1YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Build Generator"
      ],
      "metadata": {
        "id": "c40405df-1439-4661-8785-d76698df8152"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Takes in random values and reshapes it to 7x7x128\n",
        "    # Beginnings of a generated image\n",
        "    model.add(Dense(7*7*128, input_dim=128))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Reshape((7,7,128)))\n",
        "\n",
        "    # Upsampling block 1\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, 5, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Upsampling block 2\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, 5, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 1\n",
        "    model.add(Conv2D(128, 4, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 2\n",
        "    model.add(Conv2D(128, 4, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv layer to get to one channel\n",
        "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FuV3dfR5_1YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()"
      ],
      "metadata": {
        "id": "he8ajVXe_1YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "IX8SJnl1_1YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = generator.predict(np.random.randn(4,128,1))"
      ],
      "metadata": {
        "id": "bePxEBM1_1YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new fashion\n",
        "img = generator.predict(np.random.randn(4,128,1))\n",
        "# Setup the subplot formatting\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "# Loop four times and get images\n",
        "for idx, img in enumerate(img):\n",
        "    # Plot the image using a specific subplot\n",
        "    ax[idx].imshow(np.squeeze(img))\n",
        "    # Appending the image label as the plot title\n",
        "    ax[idx].title.set_text(idx)"
      ],
      "metadata": {
        "id": "0FlbHB0m_1YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Build Discriminator"
      ],
      "metadata": {
        "id": "2415abbf-24ed-4bac-8fb8-12c65017ec22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv Block\n",
        "    model.add(Conv2D(32, 5, input_shape = (28,28,1)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Second Conv Block\n",
        "    model.add(Conv2D(64, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Third Conv Block\n",
        "    model.add(Conv2D(128, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Fourth Conv Block\n",
        "    model.add(Conv2D(256, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Flatten then pass to dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "O9KgkTbg_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()"
      ],
      "metadata": {
        "id": "plad0kF7_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "EZS2jr4R_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = img[0]"
      ],
      "metadata": {
        "id": "zcOZ07mS_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "BOFcP9D4_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.predict(img)"
      ],
      "metadata": {
        "id": "9kKyJ0bp_1YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Construct Training Loop"
      ],
      "metadata": {
        "id": "39b343b0-38d3-4281-bedb-72099a18097e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Setup Losses and Optimizers"
      ],
      "metadata": {
        "id": "884abab3-2f74-442d-856f-e104ef1ac8ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam is going to be the optimizer for both\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Binary cross entropy is going to be the loss for both\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "sz671VyB_1YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_opt = Adam(learning_rate=0.0001)\n",
        "d_opt = Adam(learning_rate=0.00001)\n",
        "g_loss = BinaryCrossentropy()\n",
        "d_loss = BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "mbMmmNuo_1YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Build Subclassed Model"
      ],
      "metadata": {
        "id": "9f170b0e-f731-4cbd-8068-24896f462c08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the base model class to subclass our training step\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "WjZ8W58Y_1YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionGAN(Model):\n",
        "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "        # Pass through args and kwargs to base class\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Create attributes for gen and disc\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "\n",
        "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
        "        # Compile with base class\n",
        "        super().compile(*args, **kwargs)\n",
        "\n",
        "        # Create attributes for losses and optimizers\n",
        "        self.g_opt = g_opt\n",
        "        self.d_opt = d_opt\n",
        "        self.g_loss = g_loss\n",
        "        self.d_loss = d_loss\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        # Get the data\n",
        "        real_images = batch\n",
        "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            # Pass the real and fake images to the discriminator model\n",
        "            yhat_real = self.discriminator(real_images, training=True)\n",
        "            yhat_fake = self.discriminator(fake_images, training=True)\n",
        "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
        "\n",
        "            # Create labels for real and fakes images\n",
        "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
        "\n",
        "            # Add some noise to the TRUE outputs\n",
        "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
        "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
        "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
        "\n",
        "            # Calculate loss - BINARYCROSS\n",
        "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
        "\n",
        "        # Apply backpropagation - nn learn\n",
        "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Train the generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            # Generate some new images\n",
        "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
        "\n",
        "            # Create the predicted labels\n",
        "            predicted_labels = self.discriminator(gen_images, training=False)\n",
        "\n",
        "            # Calculate loss - trick to training to fake out the discriminator\n",
        "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
        "\n",
        "        # Apply backprop\n",
        "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
        "\n",
        "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
      ],
      "metadata": {
        "id": "1xAXUpxJ_1YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create instance of subclassed model\n",
        "fashgan = FashionGAN(generator, discriminator)"
      ],
      "metadata": {
        "id": "MfTr_Jn9_1YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
      ],
      "metadata": {
        "id": "D_jBIVoA_1YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Build Callback"
      ],
      "metadata": {
        "id": "e06d0adb-38d0-4558-b824-7416cf880082"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.callbacks import Callback"
      ],
      "metadata": {
        "id": "lmLXuLZO_1YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelMonitor(Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = array_to_img(generated_images[i])\n",
        "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
      ],
      "metadata": {
        "id": "cQ842L2I_1YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Train"
      ],
      "metadata": {
        "id": "16e2f159-25e7-4e35-95ef-f0fd18ac5897"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend 2000 epochs\n",
        "hist = fashgan.fit(ds, epochs=20, callbacks=[ModelMonitor()])"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "4ariHVp1_1YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Review Performance"
      ],
      "metadata": {
        "id": "39c665a1-a4cc-41ac-a08a-2e14ba64e88d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.suptitle('Loss')\n",
        "plt.plot(hist.history['d_loss'], label='d_loss')\n",
        "plt.plot(hist.history['g_loss'], label='g_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ZJ1ZrhM_1YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Test Out the Generator"
      ],
      "metadata": {
        "id": "d319a982-7ae5-4754-adcf-b490f17a79d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Generate Images"
      ],
      "metadata": {
        "id": "206ba81f-978a-4c31-9c3d-6ebe5a5bfc29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.load_weights(os.path.join('archive', 'generatormodel.h5'))"
      ],
      "metadata": {
        "id": "-e6fPURI_1YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = generator.predict(tf.random.normal((16, 128, 1)))"
      ],
      "metadata": {
        "id": "9dmttEix_1YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\n",
        "for r in range(4):\n",
        "    for c in range(4):\n",
        "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
      ],
      "metadata": {
        "id": "B-Kc54Cc_1YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Save the Model"
      ],
      "metadata": {
        "id": "5137cffa-784d-4076-beef-0a067b86d3aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('generator.h5')\n",
        "discriminator.save('discriminator.h5')"
      ],
      "metadata": {
        "id": "XHyBK8bO_1YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Degan"
      ],
      "metadata": {
        "id": "6qJmqSH4_1YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:07:54.511678Z",
          "iopub.execute_input": "2024-07-22T05:07:54.512197Z",
          "iopub.status.idle": "2024-07-22T05:08:00.010432Z",
          "shell.execute_reply.started": "2024-07-22T05:07:54.512146Z",
          "shell.execute_reply": "2024-07-22T05:08:00.00838Z"
        },
        "trusted": true,
        "id": "TI7RgI9__1YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the Degan model"
      ],
      "metadata": {
        "id": "Am2uVF5X_1YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:00.01208Z",
          "iopub.execute_input": "2024-07-22T05:08:00.012932Z",
          "iopub.status.idle": "2024-07-22T05:08:00.019972Z",
          "shell.execute_reply.started": "2024-07-22T05:08:00.012896Z",
          "shell.execute_reply": "2024-07-22T05:08:00.018789Z"
        },
        "trusted": true,
        "id": "tVdZIfRt_1YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First using Tensorflow keras then Pytorch"
      ],
      "metadata": {
        "id": "pal5SUPo_1YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:00.022951Z",
          "iopub.execute_input": "2024-07-22T05:08:00.023327Z",
          "iopub.status.idle": "2024-07-22T05:08:15.909808Z",
          "shell.execute_reply.started": "2024-07-22T05:08:00.023295Z",
          "shell.execute_reply": "2024-07-22T05:08:15.908636Z"
        },
        "trusted": true,
        "id": "VqcZb28c_1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T20:01:56.648954Z",
          "iopub.execute_input": "2024-07-21T20:01:56.649481Z",
          "iopub.status.idle": "2024-07-21T20:01:56.66038Z",
          "shell.execute_reply.started": "2024-07-21T20:01:56.649437Z",
          "shell.execute_reply": "2024-07-21T20:01:56.65868Z"
        },
        "trusted": true,
        "id": "44jmk6hY_1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:15.911243Z",
          "iopub.execute_input": "2024-07-22T05:08:15.912113Z",
          "iopub.status.idle": "2024-07-22T05:08:51.085792Z",
          "shell.execute_reply.started": "2024-07-22T05:08:15.912069Z",
          "shell.execute_reply": "2024-07-22T05:08:51.084346Z"
        },
        "trusted": true,
        "id": "lsaotW8Y_1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:51.22349Z",
          "iopub.execute_input": "2024-07-22T05:08:51.223902Z",
          "iopub.status.idle": "2024-07-22T05:08:51.233833Z",
          "shell.execute_reply.started": "2024-07-22T05:08:51.22387Z",
          "shell.execute_reply": "2024-07-22T05:08:51.232609Z"
        },
        "trusted": true,
        "id": "8X0k-Uaj_1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(_,_) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:51.718024Z",
          "iopub.execute_input": "2024-07-22T05:08:51.718512Z",
          "iopub.status.idle": "2024-07-22T05:08:52.044237Z",
          "shell.execute_reply.started": "2024-07-22T05:08:51.718473Z",
          "shell.execute_reply": "2024-07-22T05:08:52.043164Z"
        },
        "trusted": true,
        "id": "RZLmgM6e_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.045678Z",
          "iopub.execute_input": "2024-07-22T05:08:52.046058Z",
          "iopub.status.idle": "2024-07-22T05:08:52.114745Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.046026Z",
          "shell.execute_reply": "2024-07-22T05:08:52.113435Z"
        },
        "trusted": true,
        "id": "FgB0oZ7u_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((train_images-255)/255)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.116161Z",
          "iopub.execute_input": "2024-07-22T05:08:52.116525Z",
          "iopub.status.idle": "2024-07-22T05:08:52.244137Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.116494Z",
          "shell.execute_reply": "2024-07-22T05:08:52.242884Z"
        },
        "trusted": true,
        "id": "-q4GLn36_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.245579Z",
          "iopub.execute_input": "2024-07-22T05:08:52.245915Z",
          "iopub.status.idle": "2024-07-22T05:08:52.253989Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.245888Z",
          "shell.execute_reply": "2024-07-22T05:08:52.252696Z"
        },
        "trusted": true,
        "id": "3TaJpFqF_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = (train_images-127.5)/127.5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.255541Z",
          "iopub.execute_input": "2024-07-22T05:08:52.255962Z",
          "iopub.status.idle": "2024-07-22T05:08:52.371271Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.255925Z",
          "shell.execute_reply": "2024-07-22T05:08:52.369982Z"
        },
        "trusted": true,
        "id": "h3zWZavP_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.37301Z",
          "iopub.execute_input": "2024-07-22T05:08:52.373499Z",
          "iopub.status.idle": "2024-07-22T05:08:52.379506Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.373454Z",
          "shell.execute_reply": "2024-07-22T05:08:52.37831Z"
        },
        "trusted": true,
        "id": "zxpPrvBM_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:08:52.381188Z",
          "iopub.execute_input": "2024-07-22T05:08:52.381665Z",
          "iopub.status.idle": "2024-07-22T05:08:53.148607Z",
          "shell.execute_reply.started": "2024-07-22T05:08:52.381622Z",
          "shell.execute_reply": "2024-07-22T05:08:53.146943Z"
        },
        "trusted": true,
        "id": "LJVN3Owq_1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:10:20.702364Z",
          "iopub.execute_input": "2024-07-22T05:10:20.702812Z",
          "iopub.status.idle": "2024-07-22T05:10:21.014012Z",
          "shell.execute_reply.started": "2024-07-22T05:10:20.702778Z",
          "shell.execute_reply": "2024-07-22T05:10:21.012313Z"
        },
        "trusted": true,
        "id": "wh_nXFVi_1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Model"
      ],
      "metadata": {
        "id": "7GSkNfZ__1YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose,Input,Conv2D,Dense,Flatten,Dropout"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:47:42.799327Z",
          "iopub.execute_input": "2024-07-22T05:47:42.799761Z",
          "iopub.status.idle": "2024-07-22T05:47:42.805229Z",
          "shell.execute_reply.started": "2024-07-22T05:47:42.799727Z",
          "shell.execute_reply": "2024-07-22T05:47:42.804028Z"
        },
        "trusted": true,
        "id": "JaZ2FrNo_1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(100,)))\n",
        "    model.add(Dense(7*7*256,use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "#    upsampling and reshaping\n",
        "    model.add(Reshape((7,7,256)))\n",
        "    assert model.output_shape==(None,7,7,256)\n",
        "\n",
        "    model.add(Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False))\n",
        "    assert model.output_shape==(None,7,7,128)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
        "    assert model.output_shape == (None,14,14,64)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))\n",
        "    assert model.output_shape == (None,28,28,1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:10:25.767043Z",
          "iopub.execute_input": "2024-07-22T05:10:25.767597Z",
          "iopub.status.idle": "2024-07-22T05:10:25.783162Z",
          "shell.execute_reply.started": "2024-07-22T05:10:25.76753Z",
          "shell.execute_reply": "2024-07-22T05:10:25.781942Z"
        },
        "trusted": true,
        "id": "QleWR0el_1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:10:30.318613Z",
          "iopub.execute_input": "2024-07-22T05:10:30.319037Z",
          "iopub.status.idle": "2024-07-22T05:10:30.324638Z",
          "shell.execute_reply.started": "2024-07-22T05:10:30.319002Z",
          "shell.execute_reply": "2024-07-22T05:10:30.323225Z"
        },
        "trusted": true,
        "id": "UmbjUZm5_1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "noise = tf.random.normal([1,100])\n",
        "generator_image = generator(noise,training=False)\n",
        "plt.imshow(generator_image[0,:,:,0],cmap='gray')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:10:31.792671Z",
          "iopub.execute_input": "2024-07-22T05:10:31.793142Z",
          "iopub.status.idle": "2024-07-22T05:10:32.475233Z",
          "shell.execute_reply.started": "2024-07-22T05:10:31.793103Z",
          "shell.execute_reply": "2024-07-22T05:10:32.474075Z"
        },
        "trusted": true,
        "id": "EhpZTW4z_1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(generator_image[0,:,:,0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:10:35.687868Z",
          "iopub.execute_input": "2024-07-22T05:10:35.688399Z",
          "iopub.status.idle": "2024-07-22T05:10:35.98821Z",
          "shell.execute_reply.started": "2024-07-22T05:10:35.688354Z",
          "shell.execute_reply": "2024-07-22T05:10:35.986616Z"
        },
        "trusted": true,
        "id": "JjUTvX9P_1YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## discriminator using keras"
      ],
      "metadata": {
        "id": "L6YgL-Gj_1YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=[28,28,1]))\n",
        "    model.add(Conv2D(64,(5,5),strides=(2,2),padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:47:53.695138Z",
          "iopub.execute_input": "2024-07-22T05:47:53.695537Z",
          "iopub.status.idle": "2024-07-22T05:47:53.70459Z",
          "shell.execute_reply.started": "2024-07-22T05:47:53.695508Z",
          "shell.execute_reply": "2024-07-22T05:47:53.703325Z"
        },
        "trusted": true,
        "id": "KueN63RK_1YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generator_image)\n",
        "decision"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:49:17.072417Z",
          "iopub.execute_input": "2024-07-22T05:49:17.072897Z",
          "iopub.status.idle": "2024-07-22T05:49:17.196256Z",
          "shell.execute_reply.started": "2024-07-22T05:49:17.072861Z",
          "shell.execute_reply": "2024-07-22T05:49:17.195005Z"
        },
        "trusted": true,
        "id": "Ne1-zRHX_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T05:50:10.11478Z",
          "iopub.execute_input": "2024-07-22T05:50:10.11516Z",
          "iopub.status.idle": "2024-07-22T05:50:10.122882Z",
          "shell.execute_reply.started": "2024-07-22T05:50:10.115131Z",
          "shell.execute_reply": "2024-07-22T05:50:10.121711Z"
        },
        "trusted": true,
        "id": "E7uM15wC_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy ="
      ],
      "metadata": {
        "id": "N0eeNO6g_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-Max9IE_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRd9eMdQ_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CP5z_7eQ_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AI6RJP6f_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,channels_img,features_d):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "        nn.Conv2d(channels_img,features_d,kernel_size=4,strides=2,padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "            self._block(features_d,features_d*2,4,2,1),\n",
        "            self._block(features_d*2 , features_d*4,4,2,1),\n",
        "            self._block(features_d*4 , features_d*8,4,2,1),\n",
        "            nn.Conv2d(features_d*8,1,kernel_size=4,strides=2,padding=0),\n",
        "            nn.Sigmoid(),\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T20:00:15.533685Z",
          "iopub.execute_input": "2024-07-21T20:00:15.534077Z",
          "iopub.status.idle": "2024-07-21T20:00:15.541425Z",
          "shell.execute_reply.started": "2024-07-21T20:00:15.534049Z",
          "shell.execute_reply": "2024-07-21T20:00:15.540294Z"
        },
        "trusted": true,
        "id": "aEgY39kH_1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNqovhsR_1YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqDMpg8q_1YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJkhQ2uP_1YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "yQmYl9P2_1YX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}