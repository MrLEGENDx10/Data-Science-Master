{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  placed\n",
       "0     8              8       1\n",
       "1     7              9       1\n",
       "2     6             10       0\n",
       "3     5              5       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters['W' + str(l)] = np.ones((layer_dims[l-1],layer_dims[l])) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function formula is given by:\n",
    "\n",
    "```python\n",
    "sigmoid(z) = 1 / (1 + exp(-z))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1 /(1 + np.exp(-Z))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform linear forward propagation, we can use the following formula:\n",
    "\n",
    "Z = W^T * A_prev + b\n",
    "\n",
    "Where:\n",
    "- Z is the linear output\n",
    "- W is the weight matrix\n",
    "- A_prev is the activation from the previous layer\n",
    "- b is the bias vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W,b):\n",
    "    Z = np.dot(W.T,A_prev) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_layer feed forward\n",
    "def L_layer_forward(X,parameters):\n",
    "    A = X \n",
    "    L = len(parameters)//2 # number of layers in the neural network\n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        # print(\"A\" + str(l-1) + \": \", A_prev)\n",
    "        # print (\"W\" + str(l) + \": \", Wl)\n",
    "        # print (\"b\" + str(l) + \": \", bl)\n",
    "        # print(\"--\"*20)\n",
    "        A = linear_forward(A_prev,Wl,bl)\n",
    "    return A,A_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for parameter updation in a machine learning algorithm depends on the specific algorithm being used. Here are a few examples:\n",
    "\n",
    "1. Gradient Descent:\n",
    "    - For updating the weights: `new_weight = old_weight - learning_rate * gradient`\n",
    "    - For updating the bias: `new_bias = old_bias - learning_rate * gradient`\n",
    "\n",
    "2. Adam Optimizer:\n",
    "    - For updating the weights: `new_weight = old_weight - learning_rate * m / (sqrt(v) + epsilon)`\n",
    "    - For updating the bias: `new_bias = old_bias - learning_rate * m / (sqrt(v) + epsilon)`\n",
    "\n",
    "3. RMSprop:\n",
    "    - For updating the weights: `new_weight = old_weight - learning_rate * gradient / (sqrt(cache) + epsilon)`\n",
    "    - For updating the bias: `new_bias = old_bias - learning_rate * gradient / (sqrt(cache) + epsilon)`\n",
    "\n",
    "Please note that these are just examples, and the actual formula may vary depending on the specific algorithm and implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.01 0.01]\n",
      " [0.01 0.01]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "Loss for this student -  0.6163437730407396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.0097863, 0.0097863],\n",
       "        [0.0097863, 0.0097863]]),\n",
       " 'b1': array([[-2.67130853e-05],\n",
       "        [-2.67130853e-05]]),\n",
       " 'W2': array([[0.01036807],\n",
       "        [0.01036807]]),\n",
       " 'b2': array([[0.01041408]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa','profile_score']].values[0].reshape(2,1)\n",
    "y  = df[['placed']].values[0][0]\n",
    "\n",
    "# Parameters initialization \n",
    "parameters = initialize_parameters([2,2,1])\n",
    "y_hat , A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "print('Loss for this student - ', -y*np.log(y_hat) -(1-y) * np.log(1-y_hat))\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.0097863 0.0097863]\n",
      " [0.0097863 0.0097863]]\n",
      "b1:  [[-2.67130853e-05]\n",
      " [-2.67130853e-05]]\n",
      "----------------------------------------\n",
      "Loss for this student -  0.7744847078541179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.00988376, 0.00994873],\n",
       "        [0.01007241, 0.01026315]]),\n",
       " 'b1': array([[-1.04691433e-05],\n",
       "        [ 2.09726370e-05]]),\n",
       " 'W2': array([[0.01004463],\n",
       "        [0.00982901]]),\n",
       " 'b2': array([[0.0097751]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa','profile_score']].values[2].reshape(2,1)\n",
    "y = df[['placed']].values[2][0]\n",
    "\n",
    "y_hat , A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "print('Loss for this student - ', -y*np.log(y_hat) -(1-y) * np.log(1-y_hat))\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.00988376 0.00994873]\n",
      " [0.01007241 0.01026315]]\n",
      "b1:  [[-1.04691433e-05]\n",
      " [ 2.09726370e-05]]\n",
      "----------------------------------------\n",
      "Loss for this student -  0.7442761177567138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.00993511, 0.01000008],\n",
       "        [0.01012263, 0.01031337]]),\n",
       " 'b1': array([[-1.99390362e-07],\n",
       "        [ 3.10160190e-05]]),\n",
       " 'W2': array([[0.00978217],\n",
       "        [0.00956655]]),\n",
       " 'b2': array([[0.00951406]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['placed']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch  0  is  0.6875492800496665\n",
      "Loss after epoch  1  is  0.6875944879875241\n",
      "Loss after epoch  2  is  0.6876415586395724\n",
      "Loss after epoch  3  is  0.6876905459983084\n",
      "Loss after epoch  4  is  0.6877415060274257\n",
      "Loss after epoch  5  is  0.6877944967468718\n",
      "Loss after epoch  6  is  0.6878495783219805\n",
      "Loss after epoch  7  is  0.6879068131568984\n",
      "Loss after epoch  8  is  0.6879662659925372\n",
      "Loss after epoch  9  is  0.6880280040092983\n",
      "Loss after epoch  10  is  0.6880920969348309\n",
      "Loss after epoch  11  is  0.6881586171570994\n",
      "Loss after epoch  12  is  0.6882276398430545\n",
      "Loss after epoch  13  is  0.6882992430632175\n",
      "Loss after epoch  14  is  0.68837350792251\n",
      "Loss after epoch  15  is  0.6884505186976775\n",
      "Loss after epoch  16  is  0.6885303629816799\n",
      "Loss after epoch  17  is  0.6886131318354459\n",
      "Loss after epoch  18  is  0.6886989199474054\n",
      "Loss after epoch  19  is  0.6887878258012545\n",
      "Loss after epoch  20  is  0.6888799518524206\n",
      "Loss after epoch  21  is  0.6889754047137331\n",
      "Loss after epoch  22  is  0.6890742953508412\n",
      "Loss after epoch  23  is  0.6891767392879418\n",
      "Loss after epoch  24  is  0.689282856824432\n",
      "Loss after epoch  25  is  0.6893927732631293\n",
      "Loss after epoch  26  is  0.6895066191507497\n",
      "Loss after epoch  27  is  0.6896245305313766\n",
      "Loss after epoch  28  is  0.6897466492137061\n",
      "Loss after epoch  29  is  0.6898731230528978\n",
      "Loss after epoch  30  is  0.6900041062479245\n",
      "Loss after epoch  31  is  0.6901397596553672\n",
      "Loss after epoch  32  is  0.6902802511206689\n",
      "Loss after epoch  33  is  0.6904257558279276\n",
      "Loss after epoch  34  is  0.6905764566693813\n",
      "Loss after epoch  35  is  0.6907325446358195\n",
      "Loss after epoch  36  is  0.6908942192292366\n",
      "Loss after epoch  37  is  0.6910616888991356\n",
      "Loss after epoch  38  is  0.6912351715039853\n",
      "Loss after epoch  39  is  0.6914148947994447\n",
      "Loss after epoch  40  is  0.6916010969550722\n",
      "Loss after epoch  41  is  0.6917940271013652\n",
      "Loss after epoch  42  is  0.6919939459091039\n",
      "Loss after epoch  43  is  0.6922011262031101\n",
      "Loss after epoch  44  is  0.692415853612689\n",
      "Loss after epoch  45  is  0.6926384272611753\n",
      "Loss after epoch  46  is  0.6928691604971893\n",
      "Loss after epoch  47  is  0.6931083816703889\n",
      "Loss after epoch  48  is  0.6933564349547114\n",
      "Loss after epoch  49  is  0.6936136812223119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.00483265, -0.00341028],\n",
       "        [ 0.00247822,  0.00861316]]),\n",
       " 'b1': array([[-0.00150804],\n",
       "        [-0.00035603]]),\n",
       " 'W2': array([[0.01756846],\n",
       "        [0.01196527]]),\n",
       " 'b2': array([[0.01191562]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs =50 \n",
    "for i in range(epochs):\n",
    "    Loss =[]\n",
    "    for j in range(df.shape[0]):\n",
    "        X = df[['cgpa','profile_score']].values[j].reshape(2,1)\n",
    "        y = df[['placed']].values[j][0]\n",
    "        \n",
    "        # parameters initialization\n",
    "        y_hat,A1 = L_layer_forward(X,parameters)\n",
    "        y_hat = y_hat[0][0]\n",
    "        update_parameters(parameters,y,y_hat,A1,X)\n",
    "        Loss.append(-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
    "    print('Loss after epoch ', i, ' is ', np.mean(Loss))\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
